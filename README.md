# UCAS Deep Learning Assignment 1: Handwritten digit recognition.
## 摘要
在计算机视觉领域中，手写数字识别是一个常见的研究问题，其目标为使机器自动识别人类的手写字体。本文采取深度学习的方式，构建残差神经网络，避免在较大深度下梯度的消失，并有监督地训练模型实现手写数字识别。在实验上，本文分别构建ResNet34和ResNet50两种典型的残差神经网络模型，在基准数据集MNIST上进行实验。实验结果表明，ResNet50在该数据集上分别取得了98.94%的准确率和98.93%的Macro F1分数。相比ResNet34，其准确率和Macro F1分数分别提高0.52%和0.54%，证明50层的残差网络比34层残差网络在手写数字识别上更具优势。

## 介绍
计算机视觉是近年来持续火热的一个研究领域，其意在使计算机能够像人一样具有视觉，智能地识别和处理图片或视频等。在该领域中，手写数字识别是一个典型的任务，其目标为使计算机自动地识别人类的手写数字。该任务的难点在于，手写数字的形状、位置、大小是多样的，即使同一个数字根据人类字迹的不同也可以呈现出不同的样式。由于手写数字的多样性，基于表层像素的传统图像处理方法及基于人工特征的机器学习方法无法有效地识别手写数字，其表现为通常具有较低的准确率。

为了解决该问题，很多基于深度学习的方法被提出，用于自动地学习手写数字图像的高层特征，进而实现手写数字的识别。LeNet[1]是早期的卷积神经网络之一，其使用可学习参数的卷积在图像多个位置上提取相似特征。具体地，其使用两次卷积和下采样提取图像的高层特征，然后使用全连接层和softmax实现手写数字分类。AlexNet[2]在LeNet的卷积思想的基础上，使用ReLU作为激活函数，成功避免了Sigmoid在较深网络时出现的梯度弥散问题。其在卷积中使用重叠的最大池化，在处理多种变换的同时避免平均池化导致的模糊。同时，其还在训练过程中使用Dropout随机舍弃神经元以防止过拟合。

本文则利用ResNet[3]对图像进行处理，从而实现对手写数字的识别。ResNet中首次引入了残差块的概念，在每个残差块中，除主分支外，引入了一个恒等快捷连接以跳过一个或多个层，从而使得神经网络中的误差更好地反向传播到前面的层，进而避免梯度消失，实现更好地拟合数据。本文分别利用34层和50层的ResNet在MNIST基准数据集上进行实验。实验结果表明，ResNet50在该数据集上分别取得了98.94%的准确率和98.93%的Macro F1分数。相比ResNet34，其准确率和Macro F1分数分别提高0.52%和0.54%，证明50层的残差网络比34层残差网络在手写数字识别上更具优势。

## 解决方案
1、网络结构设计
本文分别使用ResNet34和ResNet50作为神经网络模型，实现对手写数字的识别。这两种模型的网络结构如下图所示：
 
图 1 ResNet34和ResNet50网络结构
从上图中可以发现，ResNet34和ResNet50两个网络模型的前面两层是相同的，均使用64个尺寸为7*7，步长为2的卷积核进行卷积，然后进行尺寸为3*3，步长为2的最大池化。在此之后，ResNet34和ResNet50分别使用不同结构的残差块构成网络主体。其中，ResNet34使用BasicBlock构建，而ResNet50使用Bottleneck构建。前者在主分支的两次卷积中，使用尺寸相同的卷积核。而后者有三次卷积，其中第一次和第三次卷积的卷积核尺寸为1*1，而第二次卷积的尺寸为3*3，大于第一次和第二次卷积的尺寸，形状呈瓶颈状。具体如下图所示。
 
图 2 BasicBlock和BottleNeck结构[3]
在由残差块构建的卷积层之后，加入一个平均池化层和全连接层整合信息，并最终通过softmax实现多分类。由于该网络中使用到大量的快捷连接，使得误差反向传播时能够有效避免梯度的消失，进而可以通过加深网络的网络提高模型的拟合能力。

2、损失函数设计
本文使用交叉熵作为损失函数，其主要刻画的是实际输出（概率）与期望输出（概率）的距离，也就是交叉熵的值越小，两个概率分布就越接近。其常用来作为分类问题的损失函数。假设概率分布p为期望输出，概率分布q为实际输出，则交叉熵H(p,q)的数学表达式如下：
 

## 实验结果和分析
1、数据集
本文使用MNIST作为基准数据集对模型进行评估。MNIST是一个经常用来对手写数据识别进行评估的公开数据集，在该数据集中，每个数据是一张28*28的灰度图像，图像中包含一个手写数字，并且其已经过规格化和居中等预处理，可以直接被用来对模型进行评估。MNIST数据集具有60000个训练数据和10000个测试数据，为了更好地在训练时观察模型是否已经过拟合，本文额外从训练集中划分以0.3的比例划分出验证集。最终，训练集、验证集和测试集的数据量如下表所示：
表 1 MNIST数据集中的数据量
数据集	数据量
训练集	42000
验证集	18000
测试集	10000

2、实验环境
本文中涉及的实验在配有Tesla P100 PCIE 12GB GPU, Intel Xeon Silver 4116 CPU @ 2.10GHz CPU和64GB内存的设备上进行。模型基于PyTorch深度学习平台搭建，使用Adam优化器对参数进行优化，迭代次数为10次，并使用Early Stop进一步地避免过拟合。

3、实验结果
本文中在MNIST数据集上对ResNet34和ResNet50的实验结果如下：
表 2 ResNet34和ResNet50在MNIST数据集上的实验结果
	ResNet34	ResNet50
Accuracy	98.42%	98.94%
Macro-PRECISION	98.44%	98.93%
MACRO-RECALL	98.37%	98.93%
MACRO-F1	98.39%	98.93%
如上图所示，ResNet34在MNIST数据集上的准确率、Macro-Precision、Macro-Recall和Macro-F1分别达到98.42%、98.44%、98.37%和98.39%。虽然ResNet34已经能够在MNIST上取得较好的准确率，但是在经过网络加深后的ResNet50仍表现出性能的提升。具体地，ResNet50该数据集上的准确率、Macro-Precision、Macro-Recall和Macro-F1分别达到98.94%、98.93%、98.93%和98.93%。其中准确率、Macro-Precision、Macro-Recall和Macro-F1的提升分别达到0.52%、0.49%、0.56和0.54%。由于ResNet50相较ResNet34具有更深的网络层数，并且在其残差块中，对特征的处理更加充分，所以ResNet50具有更强的学习能力，进而导致其具有更高的准确率。
除此之外，本文还对比了ResNet34和ResNet50在训练过程中收敛速率以及最终验证集准确率。实验结果如图3所示，可以发现，在左图中，代表ResNet34的橙线明显处于代表ResNet50的蓝线下方，这表明ResNet34在训练集上的速率略微快于ResNet50。由于ResNet50的网络相较ResNet34较深，所以其需要更多的迭代次数对参数进行优化。在右图中，可以发现虽然在前几次迭代中，ResNet34在验证集上的准确率高于ResNet50，但是在最终收敛时，由于ResNet50更强的学习能力，其准确率略高于ResNet34。
 
图 3 ResNet34和ResNet50收敛速率比较

4.  结论
针对传统图像处理方法无法有效识别手写数字的问题，本文利用深度学习技术，搭建34层和50层的残差网络，避免梯度消失的情况下，提取图像的高层特征，从而实现手写字体识别。在模型评估上，本文从准确率、精确率、召回率和F1分数和收敛速度等角度对模型的性能进行评估。实验结果表明，虽然ResNet50的收敛速度略慢于ResNet34，但由于其更强的特征学习能力，其准确率和Macro F1分数分别提高0.52%和0.54%，证明50层的残差网络比34层残差网络在手写数字识别上更具优势。

参考文献
[1] Lecun Y, Bottou L, Bengio Y, Haffner P. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 1998, 86(11): 2278-2324.
[2] Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 2012: 1097-1105.
[3] He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. Proceedings of the IEEE conference on computer vision and pattern recognition, 2016: 770-778.


